{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neural_network as NN\n",
    "import sklearn.model_selection\n",
    "import scipy.stats\n",
    "from AbstractBaseCollabFilterSGD import AbstractBaseCollabFilterSGD\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "    load_train_valid_test_datasets()\n",
    "user_info = pd.read_csv('./data_movie_lens_100k/user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and initialize its parameters\n",
    "# to have right scale as the dataset (right num users and items)\n",
    "model = CollabFilterOneVectorPerItem(\n",
    "    n_epochs=156, batch_size=508, step_size=0.8108726428612864,\n",
    "    alpha=0.061177501974355154, n_factors=170)\n",
    "model.init_parameter_dict(n_users, n_items, train_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with SGD\n",
    "model.fit(train_tuple, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "yhat_model_tr = model.predict(train_tuple[0], train_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "yhat_model_va = model.predict(valid_tuple[0], valid_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "yhat_model_te = model.predict(test_tuple[0], test_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_N = train_tuple[2] - yhat_model_tr\n",
    "y_va_M = valid_tuple[2] - yhat_model_va\n",
    "y_te_L = test_tuple[2] - yhat_model_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "x_tr_NF = ag_np.empty((len(train_tuple[0]), 346))\n",
    "for i in range(len(train_tuple[0])):\n",
    "    user_id = train_tuple[0][i]\n",
    "    item_id = train_tuple[1][i]\n",
    "    x_tr_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_tr[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][train_tuple[0][i]]], [user_info['is_male'][train_tuple[0][i]]]))\n",
    "\n",
    "pDict = model.param_dict\n",
    "x_va_MF = ag_np.empty((len(valid_tuple[0]), 346))\n",
    "for i in range(len(valid_tuple[0])):\n",
    "    user_id = valid_tuple[0][i]\n",
    "    item_id = valid_tuple[1][i]\n",
    "    x_va_MF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_va[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][valid_tuple[0][i]]], [user_info['is_male'][valid_tuple[0][i]]]))\n",
    "\n",
    "pDict = model.param_dict\n",
    "x_te_LF = ag_np.empty((len(test_tuple[0]), 346))\n",
    "for i in range(len(test_tuple[0])):\n",
    "    user_id = test_tuple[0][i]\n",
    "    item_id = test_tuple[1][i]\n",
    "    x_te_LF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_te[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][test_tuple[0][i]]], [user_info['is_male'][test_tuple[0][i]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NN.MLPRegressor(\n",
    "    hidden_layer_sizes=[32],\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=[32], max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_va_MF, y_va_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = mlp.predict(x_te_LF) + yhat_model_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713054268774339\n"
     ]
    }
   ],
   "source": [
    "mae_model = ag_np.mean(ag_np.absolute(yhat_model_te - test_tuple[2]))\n",
    "print(mae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7193858889676837\n"
     ]
    }
   ],
   "source": [
    "mae = ag_np.mean(ag_np.absolute(yhat - test_tuple[2]))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scoring_metric_name = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_N2 = ag_np.vstack([x_va_MF, x_te_LF])\n",
    "yall_N = ag_np.hstack([y_va_M, y_te_L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_N = ag_np.hstack([\n",
    "    -1 * ag_np.ones(y_va_M.size), # -1 means never include this example in any test split\n",
    "    0  * ag_np.ones(y_te_L.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splitter only produces one split and it is the intended one\n",
    "for tr_idx, te_idx in my_splitter.split(xall_N2, yall_N):\n",
    "    assert ag_np.allclose(xall_N2[te_idx], x_te_LF)\n",
    "    assert ag_np.allclose(yall_N[te_idx], y_te_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_distributions_by_name = dict(\n",
    "    hidden_layer_sizes=scipy.stats.randint(10, 150),\n",
    "    alpha=scipy.stats.uniform(0.0, 1.0),\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        13, 169,\n",
    "        ],\n",
    "    max_iter=scipy.stats.randint(20, 1000)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_rand_search = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rand_searcher = sklearn.model_selection.RandomizedSearchCV(\n",
    "    mlp,\n",
    "    my_parameter_distributions_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    n_iter=n_trials_rand_search,\n",
    "    random_state=13, # same seed means same results everytime we repeat this code\n",
    "    verbose=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 16 candidates, totalling 16 fits\n",
      "[CV] alpha=0.7777024105738202, hidden_layer_sizes=84, max_iter=548, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   53.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7777024105738202, hidden_layer_sizes=84, max_iter=548, random_state=13, score=-0.719, total=  53.8s\n",
      "[CV] alpha=0.8929826912712245, hidden_layer_sizes=136, max_iter=982, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.8929826912712245, hidden_layer_sizes=136, max_iter=982, random_state=13, score=-0.720, total= 2.5min\n",
      "[CV] alpha=0.6416133447590692, hidden_layer_sizes=84, max_iter=861, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6416133447590692, hidden_layer_sizes=84, max_iter=861, random_state=169, score=-0.720, total= 1.4min\n",
      "[CV] alpha=0.2984494708891794, hidden_layer_sizes=149, max_iter=490, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.2984494708891794, hidden_layer_sizes=149, max_iter=490, random_state=169, score=-0.719, total= 1.4min\n",
      "[CV] alpha=0.44626619112700183, hidden_layer_sizes=34, max_iter=432, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.44626619112700183, hidden_layer_sizes=34, max_iter=432, random_state=169, score=-0.716, total=  22.9s\n",
      "[CV] alpha=0.6144541007156207, hidden_layer_sizes=68, max_iter=554, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6144541007156207, hidden_layer_sizes=68, max_iter=554, random_state=13, score=-0.718, total=  52.0s\n",
      "[CV] alpha=0.21789900913168891, hidden_layer_sizes=143, max_iter=140, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.21789900913168891, hidden_layer_sizes=143, max_iter=140, random_state=169, score=-0.717, total=  24.3s\n",
      "[CV] alpha=0.6244325270137528, hidden_layer_sizes=59, max_iter=556, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6244325270137528, hidden_layer_sizes=59, max_iter=556, random_state=169, score=-0.717, total=  43.1s\n",
      "[CV] alpha=0.05283655977782398, hidden_layer_sizes=81, max_iter=923, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05283655977782398, hidden_layer_sizes=81, max_iter=923, random_state=169, score=-0.722, total= 1.5min\n",
      "[CV] alpha=0.8128411710026234, hidden_layer_sizes=16, max_iter=275, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.8128411710026234, hidden_layer_sizes=16, max_iter=275, random_state=169, score=-0.716, total=   8.2s\n",
      "[CV] alpha=0.5092622000835182, hidden_layer_sizes=96, max_iter=186, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.5092622000835182, hidden_layer_sizes=96, max_iter=186, random_state=169, score=-0.717, total=  20.5s\n",
      "[CV] alpha=0.6681904420257511, hidden_layer_sizes=148, max_iter=812, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6681904420257511, hidden_layer_sizes=148, max_iter=812, random_state=13, score=-0.721, total= 2.3min\n",
      "[CV] alpha=0.7122326779115835, hidden_layer_sizes=71, max_iter=210, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7122326779115835, hidden_layer_sizes=71, max_iter=210, random_state=13, score=-0.718, total=  20.6s\n",
      "[CV] alpha=0.6181132100183178, hidden_layer_sizes=15, max_iter=276, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6181132100183178, hidden_layer_sizes=15, max_iter=276, random_state=169, score=-0.717, total=   9.8s\n",
      "[CV] alpha=0.2444757021979903, hidden_layer_sizes=51, max_iter=264, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.2444757021979903, hidden_layer_sizes=51, max_iter=264, random_state=169, score=-0.717, total=  21.9s\n",
      "[CV] alpha=0.37933329148306616, hidden_layer_sizes=69, max_iter=348, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.37933329148306616, hidden_layer_sizes=69, max_iter=348, random_state=169, score=-0.717, total=  29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=MLPRegressor(hidden_layer_sizes=[32],\n",
       "                                          max_iter=1000, solver='lbfgs'),\n",
       "                   n_iter=16,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa0f53d3fd0>,\n",
       "                                        'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa0c9667e20>,\n",
       "                                        'max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa0f53c6610>,\n",
       "                                        'random_state': [13, 169]},\n",
       "                   random_state=13, scoring='neg_mean_absolute_error',\n",
       "                   verbose=4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rand_searcher.fit(xall_N2, yall_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (16, 13)\n",
      "Dataframe has columns:\n",
      "-- mean_fit_time\n",
      "-- std_fit_time\n",
      "-- mean_score_time\n",
      "-- std_score_time\n",
      "-- param_alpha\n",
      "-- param_hidden_layer_sizes\n",
      "-- param_max_iter\n",
      "-- param_random_state\n",
      "-- params\n",
      "-- split0_test_score\n",
      "-- mean_test_score\n",
      "-- std_test_score\n",
      "-- rank_test_score\n"
     ]
    }
   ],
   "source": [
    "rsearch_results_df = pd.DataFrame(my_rand_searcher.cv_results_).copy()\n",
    "print(\"Dataframe has shape: %s\" % (str(rsearch_results_df.shape)))\n",
    "\n",
    "print(\"Dataframe has columns:\")\n",
    "for c in rsearch_results_df.columns:\n",
    "    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>0.777702</td>\n",
       "      <td>13</td>\n",
       "      <td>548</td>\n",
       "      <td>-0.718615</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>0.892983</td>\n",
       "      <td>13</td>\n",
       "      <td>982</td>\n",
       "      <td>-0.720323</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>0.641613</td>\n",
       "      <td>169</td>\n",
       "      <td>861</td>\n",
       "      <td>-0.720062</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>0.298449</td>\n",
       "      <td>169</td>\n",
       "      <td>490</td>\n",
       "      <td>-0.718680</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>0.446266</td>\n",
       "      <td>169</td>\n",
       "      <td>432</td>\n",
       "      <td>-0.716421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68</td>\n",
       "      <td>0.614454</td>\n",
       "      <td>13</td>\n",
       "      <td>554</td>\n",
       "      <td>-0.717714</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>143</td>\n",
       "      <td>0.217899</td>\n",
       "      <td>169</td>\n",
       "      <td>140</td>\n",
       "      <td>-0.716840</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59</td>\n",
       "      <td>0.624433</td>\n",
       "      <td>169</td>\n",
       "      <td>556</td>\n",
       "      <td>-0.716906</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0528366</td>\n",
       "      <td>169</td>\n",
       "      <td>923</td>\n",
       "      <td>-0.721518</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>0.812841</td>\n",
       "      <td>169</td>\n",
       "      <td>275</td>\n",
       "      <td>-0.715605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96</td>\n",
       "      <td>0.509262</td>\n",
       "      <td>169</td>\n",
       "      <td>186</td>\n",
       "      <td>-0.716691</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>148</td>\n",
       "      <td>0.66819</td>\n",
       "      <td>13</td>\n",
       "      <td>812</td>\n",
       "      <td>-0.721496</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71</td>\n",
       "      <td>0.712233</td>\n",
       "      <td>13</td>\n",
       "      <td>210</td>\n",
       "      <td>-0.717706</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.618113</td>\n",
       "      <td>169</td>\n",
       "      <td>276</td>\n",
       "      <td>-0.716806</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>51</td>\n",
       "      <td>0.244476</td>\n",
       "      <td>169</td>\n",
       "      <td>264</td>\n",
       "      <td>-0.716869</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>69</td>\n",
       "      <td>0.379333</td>\n",
       "      <td>169</td>\n",
       "      <td>348</td>\n",
       "      <td>-0.717275</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_hidden_layer_sizes param_alpha param_random_state param_max_iter  \\\n",
       "0                        84    0.777702                 13            548   \n",
       "1                       136    0.892983                 13            982   \n",
       "2                        84    0.641613                169            861   \n",
       "3                       149    0.298449                169            490   \n",
       "4                        34    0.446266                169            432   \n",
       "5                        68    0.614454                 13            554   \n",
       "6                       143    0.217899                169            140   \n",
       "7                        59    0.624433                169            556   \n",
       "8                        81   0.0528366                169            923   \n",
       "9                        16    0.812841                169            275   \n",
       "10                       96    0.509262                169            186   \n",
       "11                      148     0.66819                 13            812   \n",
       "12                       71    0.712233                 13            210   \n",
       "13                       15    0.618113                169            276   \n",
       "14                       51    0.244476                169            264   \n",
       "15                       69    0.379333                169            348   \n",
       "\n",
       "    split0_test_score  rank_test_score  \n",
       "0           -0.718615               11  \n",
       "1           -0.720323               14  \n",
       "2           -0.720062               13  \n",
       "3           -0.718680               12  \n",
       "4           -0.716421                2  \n",
       "5           -0.717714               10  \n",
       "6           -0.716840                5  \n",
       "7           -0.716906                7  \n",
       "8           -0.721518               16  \n",
       "9           -0.715605                1  \n",
       "10          -0.716691                3  \n",
       "11          -0.721496               15  \n",
       "12          -0.717706                9  \n",
       "13          -0.716806                4  \n",
       "14          -0.716869                6  \n",
       "15          -0.717275                8  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state', 'param_max_iter']\n",
    "rsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(alpha=0.8128411710026234, hidden_layer_sizes=16, max_iter=275,\n",
      "             random_state=169, solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "print(bestr_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = (ag_np.concatenate((valid_tuple[0], test_tuple[0])),\n",
    "            ag_np.concatenate((valid_tuple[1], test_tuple[1])),\n",
    "            ag_np.concatenate((valid_tuple[2], test_tuple[2])))\n",
    "# Fit the model with SGD\n",
    "#model.fit(all_data, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_model_final = model.predict(all_data[0], all_data[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "y_final_N = all_data[2] - yhat_model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "x_final_NF = ag_np.empty((len(all_data[0]), 346))\n",
    "for i in range(len(all_data[0])):\n",
    "    user_id = all_data[0][i]\n",
    "    item_id = all_data[1][i]\n",
    "    x_final_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_final[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][all_data[0][i]]], [user_info['is_male'][all_data[0][i]]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=0.8128411710026234, hidden_layer_sizes=16, max_iter=275,\n",
       "             random_state=169, solver='lbfgs')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "bestr_mlp.fit(x_final_NF, y_final_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.82678153 4.25898307 3.71281202 ... 4.28046232 3.397163   2.91977935]\n",
      "             0\n",
      "0     3.826782\n",
      "1     4.258983\n",
      "2     3.712812\n",
      "3     3.563962\n",
      "4     4.536685\n",
      "...        ...\n",
      "9995  3.754703\n",
      "9996  4.277174\n",
      "9997  4.280462\n",
      "9998  3.397163\n",
      "9999  2.919779\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "select_movies_df = pd.read_csv(\"./data_movie_lens_100k/ratings_masked_leaderboard_set.csv\")\n",
    "leaderboard_user_id = select_movies_df[\"user_id\"]\n",
    "leaderboard_item_id = select_movies_df[\"item_id\"]\n",
    "\n",
    "yhat_model_preds = model.predict(leaderboard_user_id, leaderboard_item_id, pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "\n",
    "x_preds_NF = ag_np.empty((len(leaderboard_user_id), 346))\n",
    "for i in range(len(leaderboard_user_id)):\n",
    "    user_id = leaderboard_user_id[i]\n",
    "    item_id = leaderboard_item_id[i]\n",
    "    x_preds_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_preds[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][leaderboard_user_id[i]]], [user_info['is_male'][leaderboard_user_id[i]]]))\n",
    "\n",
    "yhat = bestr_mlp.predict(x_preds_NF) + yhat_model_preds\n",
    "\n",
    "print(yhat)\n",
    "yhat_df = pd.DataFrame(yhat)\n",
    "print(yhat_df)\n",
    "yhat_df.to_csv(r'predicted_ratings_leaderboard.txt', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
