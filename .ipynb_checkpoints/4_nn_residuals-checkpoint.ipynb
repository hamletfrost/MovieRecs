{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neural_network as NN\n",
    "import sklearn.model_selection\n",
    "import scipy.stats\n",
    "from AbstractBaseCollabFilterSGD import AbstractBaseCollabFilterSGD\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "    load_train_valid_test_datasets()\n",
    "user_info = pd.read_csv('./data_movie_lens_100k/user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and initialize its parameters\n",
    "# to have right scale as the dataset (right num users and items)\n",
    "model = CollabFilterOneVectorPerItem(\n",
    "    n_epochs=10, batch_size=1000, step_size=0.9,\n",
    "    alpha=0, n_factors=50)\n",
    "model.init_parameter_dict(n_users, n_items, train_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     1.50100 | train_MAE     1.00262 | valid_MAE     1.00801 | grad_wrt_mu     0.93400 | grad_wrt_b_per_user     0.00164 | grad_wrt_c_per_item     0.00095 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.014 | loss_total     1.33303 | train_MAE     0.90895 | valid_MAE     0.90623 | grad_wrt_mu     0.66030 | grad_wrt_b_per_user     0.00148 | grad_wrt_c_per_item     0.00084 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.029 | loss_total     1.28150 | train_MAE     0.97313 | valid_MAE     0.97625 | grad_wrt_mu     0.52353 | grad_wrt_b_per_user     0.00150 | grad_wrt_c_per_item     0.00091 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.043 | loss_total     1.30380 | train_MAE     0.92011 | valid_MAE     0.91874 | grad_wrt_mu     0.26083 | grad_wrt_b_per_user     0.00142 | grad_wrt_c_per_item     0.00085 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.129 | loss_total     1.11861 | train_MAE     0.93345 | valid_MAE     0.93437 | grad_wrt_mu     0.09920 | grad_wrt_b_per_user     0.00130 | grad_wrt_c_per_item     0.00079 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.257 | loss_total     1.26711 | train_MAE     0.91605 | valid_MAE     0.91697 | grad_wrt_mu     0.12399 | grad_wrt_b_per_user     0.00148 | grad_wrt_c_per_item     0.00083 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.386 | loss_total     1.20820 | train_MAE     0.92079 | valid_MAE     0.92362 | grad_wrt_mu     0.03831 | grad_wrt_b_per_user     0.00139 | grad_wrt_c_per_item     0.00084 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.500 | loss_total     1.14912 | train_MAE     0.90490 | valid_MAE     0.90767 | grad_wrt_mu     0.03896 | grad_wrt_b_per_user     0.00127 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.629 | loss_total     1.12044 | train_MAE     0.89803 | valid_MAE     0.90172 | grad_wrt_mu     0.05895 | grad_wrt_b_per_user     0.00128 | grad_wrt_c_per_item     0.00080 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.757 | loss_total     1.11972 | train_MAE     0.90833 | valid_MAE     0.91430 | grad_wrt_mu     0.29080 | grad_wrt_b_per_user     0.00132 | grad_wrt_c_per_item     0.00078 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.886 | loss_total     1.07281 | train_MAE     0.87431 | valid_MAE     0.87844 | grad_wrt_mu     0.18913 | grad_wrt_b_per_user     0.00129 | grad_wrt_c_per_item     0.00076 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.000 | loss_total     1.09629 | train_MAE     0.87464 | valid_MAE     0.87993 | grad_wrt_mu     0.16658 | grad_wrt_b_per_user     0.00123 | grad_wrt_c_per_item     0.00076 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.129 | loss_total     1.07031 | train_MAE     0.88328 | valid_MAE     0.89054 | grad_wrt_mu     0.26213 | grad_wrt_b_per_user     0.00126 | grad_wrt_c_per_item     0.00076 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.257 | loss_total     1.12976 | train_MAE     0.85067 | valid_MAE     0.85605 | grad_wrt_mu     0.19736 | grad_wrt_b_per_user     0.00126 | grad_wrt_c_per_item     0.00074 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.386 | loss_total     1.13397 | train_MAE     0.86905 | valid_MAE     0.87711 | grad_wrt_mu     0.20151 | grad_wrt_b_per_user     0.00131 | grad_wrt_c_per_item     0.00082 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.500 | loss_total     1.01737 | train_MAE     0.86015 | valid_MAE     0.86833 | grad_wrt_mu     0.08070 | grad_wrt_b_per_user     0.00118 | grad_wrt_c_per_item     0.00073 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.629 | loss_total     1.04251 | train_MAE     0.85405 | valid_MAE     0.86229 | grad_wrt_mu     0.01054 | grad_wrt_b_per_user     0.00116 | grad_wrt_c_per_item     0.00073 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.757 | loss_total     1.04909 | train_MAE     0.84627 | valid_MAE     0.85475 | grad_wrt_mu     0.16009 | grad_wrt_b_per_user     0.00125 | grad_wrt_c_per_item     0.00076 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.886 | loss_total     1.16416 | train_MAE     0.82512 | valid_MAE     0.83125 | grad_wrt_mu     0.51096 | grad_wrt_b_per_user     0.00132 | grad_wrt_c_per_item     0.00080 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.000 | loss_total     1.02648 | train_MAE     0.82776 | valid_MAE     0.83563 | grad_wrt_mu     0.14379 | grad_wrt_b_per_user     0.00117 | grad_wrt_c_per_item     0.00072 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.500 | loss_total     1.05362 | train_MAE     0.82451 | valid_MAE     0.83439 | grad_wrt_mu     0.06177 | grad_wrt_b_per_user     0.00121 | grad_wrt_c_per_item     0.00071 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.000 | loss_total     1.03112 | train_MAE     0.81006 | valid_MAE     0.82079 | grad_wrt_mu     0.08393 | grad_wrt_b_per_user     0.00121 | grad_wrt_c_per_item     0.00069 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.500 | loss_total     1.00827 | train_MAE     0.79347 | valid_MAE     0.80360 | grad_wrt_mu     0.23920 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00065 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.000 | loss_total     0.99082 | train_MAE     0.78779 | valid_MAE     0.79912 | grad_wrt_mu     0.16703 | grad_wrt_b_per_user     0.00117 | grad_wrt_c_per_item     0.00071 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.500 | loss_total     0.99259 | train_MAE     0.78735 | valid_MAE     0.80048 | grad_wrt_mu     0.02057 | grad_wrt_b_per_user     0.00115 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.000 | loss_total     0.97879 | train_MAE     0.77603 | valid_MAE     0.78826 | grad_wrt_mu     0.18198 | grad_wrt_b_per_user     0.00113 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.500 | loss_total     0.96666 | train_MAE     0.77401 | valid_MAE     0.78757 | grad_wrt_mu     0.01924 | grad_wrt_b_per_user     0.00109 | grad_wrt_c_per_item     0.00064 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.000 | loss_total     0.95177 | train_MAE     0.79781 | valid_MAE     0.81469 | grad_wrt_mu     0.41562 | grad_wrt_b_per_user     0.00118 | grad_wrt_c_per_item     0.00073 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.500 | loss_total     0.93927 | train_MAE     0.77330 | valid_MAE     0.78915 | grad_wrt_mu     0.05007 | grad_wrt_b_per_user     0.00118 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.000 | loss_total     0.93383 | train_MAE     0.76565 | valid_MAE     0.78135 | grad_wrt_mu     0.07358 | grad_wrt_b_per_user     0.00110 | grad_wrt_c_per_item     0.00063 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.500 | loss_total     0.92684 | train_MAE     0.76830 | valid_MAE     0.78503 | grad_wrt_mu     0.14845 | grad_wrt_b_per_user     0.00103 | grad_wrt_c_per_item     0.00066 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       8.000 | loss_total     0.92310 | train_MAE     0.75872 | valid_MAE     0.77481 | grad_wrt_mu     0.04105 | grad_wrt_b_per_user     0.00107 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.000 | loss_total     0.91336 | train_MAE     0.75811 | valid_MAE     0.77584 | grad_wrt_mu     0.05960 | grad_wrt_b_per_user     0.00114 | grad_wrt_c_per_item     0.00067 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.986 | loss_total     0.90947 | train_MAE     0.75121 | valid_MAE     0.76872 | grad_wrt_mu     0.09848 | grad_wrt_b_per_user     0.00112 | grad_wrt_c_per_item     0.00062 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with SGD\n",
    "model.fit(train_tuple, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "yhat_model_tr = model.predict(train_tuple[0], train_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "yhat_model_va = model.predict(valid_tuple[0], valid_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_N = train_tuple[2] - yhat_model_tr\n",
    "y_va_M = valid_tuple[2] - yhat_model_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "x_tr_NF = ag_np.empty((len(train_tuple[0]), 106))\n",
    "for i in range(len(train_tuple[0])):\n",
    "    user_id = train_tuple[0][i]\n",
    "    item_id = train_tuple[1][i]\n",
    "    x_tr_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_tr[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][train_tuple[0][i]]], [user_info['is_male'][train_tuple[0][i]]]))\n",
    "\n",
    "pDict = model.param_dict\n",
    "x_va_MF = ag_np.empty((len(valid_tuple[0]), 106))\n",
    "for i in range(len(valid_tuple[0])):\n",
    "    user_id = valid_tuple[0][i]\n",
    "    item_id = valid_tuple[1][i]\n",
    "    x_va_MF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_va[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][valid_tuple[0][i]]], [user_info['is_male'][valid_tuple[0][i]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NN.MLPRegressor(\n",
    "    hidden_layer_sizes=[32],\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=[32], max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = mlp.predict(x_va_MF) + yhat_model_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7780449277653884\n"
     ]
    }
   ],
   "source": [
    "mae_model = ag_np.mean(ag_np.absolute(yhat_model_va - valid_tuple[2]))\n",
    "print(mae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7632915219476523\n"
     ]
    }
   ],
   "source": [
    "mae = ag_np.mean(ag_np.absolute(yhat - valid_tuple[2]))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scoring_metric_name = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_N2 = ag_np.vstack([x_tr_NF, x_va_MF])\n",
    "yall_N = ag_np.hstack([y_tr_N, y_va_M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_N = ag_np.hstack([\n",
    "    -1 * ag_np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * ag_np.ones(y_va_M.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splitter only produces one split and it is the intended one\n",
    "for tr_idx, te_idx in my_splitter.split(xall_N2, yall_N):\n",
    "    assert ag_np.allclose(xall_N2[te_idx], x_va_MF)\n",
    "    assert ag_np.allclose(yall_N[te_idx], y_va_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_distributions_by_name = dict(\n",
    "    hidden_layer_sizes=scipy.stats.randint(10, 100),\n",
    "    alpha=scipy.stats.uniform(0.0, 1.0),\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        13, 169,\n",
    "        ],\n",
    "    max_iter=scipy.stats.randint(20, 500)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_rand_search = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rand_searcher = sklearn.model_selection.RandomizedSearchCV(\n",
    "    mlp,\n",
    "    my_parameter_distributions_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    n_iter=n_trials_rand_search,\n",
    "    random_state=13, # same seed means same results everytime we repeat this code\n",
    "    verbose=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 16 candidates, totalling 16 fits\n",
      "[CV] alpha=0.7777024105738202, hidden_layer_sizes=84, max_iter=36, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7777024105738202, hidden_layer_sizes=84, max_iter=36, random_state=13, score=-0.764, total=  18.2s\n",
      "[CV] alpha=0.8929826912712245, hidden_layer_sizes=35, max_iter=256, random_state=13 \n",
      "[CV]  alpha=0.8929826912712245, hidden_layer_sizes=35, max_iter=256, random_state=13, score=-0.763, total=   9.4s\n",
      "[CV] alpha=0.4534492474173122, hidden_layer_sizes=76, max_iter=450, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   27.6s remaining:    0.0s\n",
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.4534492474173122, hidden_layer_sizes=76, max_iter=450, random_state=13, score=-0.759, total= 3.4min\n",
      "[CV] alpha=0.38804298432184925, hidden_layer_sizes=84, max_iter=349, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.38804298432184925, hidden_layer_sizes=84, max_iter=349, random_state=169, score=-0.763, total= 3.2min\n",
      "[CV] alpha=0.2984494708891794, hidden_layer_sizes=42, max_iter=423, random_state=169 \n",
      "[CV]  alpha=0.2984494708891794, hidden_layer_sizes=42, max_iter=423, random_state=169, score=-0.763, total=   9.0s\n",
      "[CV] alpha=0.47159228006641585, hidden_layer_sizes=96, max_iter=95, random_state=169 \n",
      "[CV]  alpha=0.47159228006641585, hidden_layer_sizes=96, max_iter=95, random_state=169, score=-0.763, total=  31.5s\n",
      "[CV] alpha=0.5305754270224363, hidden_layer_sizes=38, max_iter=31, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.5305754270224363, hidden_layer_sizes=38, max_iter=31, random_state=13, score=-0.763, total=   7.3s\n",
      "[CV] alpha=0.35833378270496974, hidden_layer_sizes=32, max_iter=310, random_state=13 \n",
      "[CV]  alpha=0.35833378270496974, hidden_layer_sizes=32, max_iter=310, random_state=13, score=-0.763, total=   9.9s\n",
      "[CV] alpha=0.9391065487220239, hidden_layer_sizes=15, max_iter=140, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.9391065487220239, hidden_layer_sizes=15, max_iter=140, random_state=169, score=-0.762, total=  22.9s\n",
      "[CV] alpha=0.6244325270137528, hidden_layer_sizes=95, max_iter=325, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6244325270137528, hidden_layer_sizes=95, max_iter=325, random_state=13, score=-0.760, total= 3.9min\n",
      "[CV] alpha=0.8738134432795387, hidden_layer_sizes=55, max_iter=347, random_state=169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.8738134432795387, hidden_layer_sizes=55, max_iter=347, random_state=169, score=-0.761, total= 2.7min\n",
      "[CV] alpha=0.5258438573244301, hidden_layer_sizes=16, max_iter=275, random_state=169 \n",
      "[CV]  alpha=0.5258438573244301, hidden_layer_sizes=16, max_iter=275, random_state=169, score=-0.763, total=   2.6s\n",
      "[CV] alpha=0.5092622000835182, hidden_layer_sizes=96, max_iter=186, random_state=169 \n",
      "[CV]  alpha=0.5092622000835182, hidden_layer_sizes=96, max_iter=186, random_state=169, score=-0.763, total=  26.4s\n",
      "[CV] alpha=0.6681904420257511, hidden_layer_sizes=20, max_iter=300, random_state=13 \n",
      "[CV]  alpha=0.6681904420257511, hidden_layer_sizes=20, max_iter=300, random_state=13, score=-0.763, total=   4.5s\n",
      "[CV] alpha=0.7122326779115835, hidden_layer_sizes=71, max_iter=210, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7122326779115835, hidden_layer_sizes=71, max_iter=210, random_state=13, score=-0.761, total= 1.1min\n",
      "[CV] alpha=0.6181132100183178, hidden_layer_sizes=15, max_iter=276, random_state=169 \n",
      "[CV]  alpha=0.6181132100183178, hidden_layer_sizes=15, max_iter=276, random_state=169, score=-0.763, total=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 16.7min finished\n",
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=MLPRegressor(hidden_layer_sizes=[32],\n",
       "                                          max_iter=1000, solver='lbfgs'),\n",
       "                   n_iter=16,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f972d995f70>,\n",
       "                                        'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f972d995a90>,\n",
       "                                        'max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f972d995d90>,\n",
       "                                        'random_state': [13, 169]},\n",
       "                   random_state=13, scoring='neg_mean_absolute_error',\n",
       "                   verbose=4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rand_searcher.fit(xall_N2, yall_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (16, 13)\n",
      "Dataframe has columns:\n",
      "-- mean_fit_time\n",
      "-- std_fit_time\n",
      "-- mean_score_time\n",
      "-- std_score_time\n",
      "-- param_alpha\n",
      "-- param_hidden_layer_sizes\n",
      "-- param_max_iter\n",
      "-- param_random_state\n",
      "-- params\n",
      "-- split0_test_score\n",
      "-- mean_test_score\n",
      "-- std_test_score\n",
      "-- rank_test_score\n"
     ]
    }
   ],
   "source": [
    "rsearch_results_df = pd.DataFrame(my_rand_searcher.cv_results_).copy()\n",
    "print(\"Dataframe has shape: %s\" % (str(rsearch_results_df.shape)))\n",
    "\n",
    "print(\"Dataframe has columns:\")\n",
    "for c in rsearch_results_df.columns:\n",
    "    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>0.777702</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.763776</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0.892983</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.763308</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>0.453449</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.759324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>0.388043</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.763393</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.298449</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.763298</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>0.471592</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.763335</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>0.530575</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.763260</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.358334</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.763305</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.762337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95</td>\n",
       "      <td>0.624433</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.760466</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55</td>\n",
       "      <td>0.873813</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.760649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0.525844</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.763313</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>96</td>\n",
       "      <td>0.509262</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.763322</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>0.66819</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.763311</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>71</td>\n",
       "      <td>0.712233</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.760741</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.618113</td>\n",
       "      <td>169</td>\n",
       "      <td>-0.763285</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_hidden_layer_sizes param_alpha param_random_state  split0_test_score  \\\n",
       "0                        84    0.777702                 13          -0.763776   \n",
       "1                        35    0.892983                 13          -0.763308   \n",
       "2                        76    0.453449                 13          -0.759324   \n",
       "3                        84    0.388043                169          -0.763393   \n",
       "4                        42    0.298449                169          -0.763298   \n",
       "5                        96    0.471592                169          -0.763335   \n",
       "6                        38    0.530575                 13          -0.763260   \n",
       "7                        32    0.358334                 13          -0.763305   \n",
       "8                        15    0.939107                169          -0.762337   \n",
       "9                        95    0.624433                 13          -0.760466   \n",
       "10                       55    0.873813                169          -0.760649   \n",
       "11                       16    0.525844                169          -0.763313   \n",
       "12                       96    0.509262                169          -0.763322   \n",
       "13                       20     0.66819                 13          -0.763311   \n",
       "14                       71    0.712233                 13          -0.760741   \n",
       "15                       15    0.618113                169          -0.763285   \n",
       "\n",
       "    rank_test_score  \n",
       "0                16  \n",
       "1                10  \n",
       "2                 1  \n",
       "3                15  \n",
       "4                 8  \n",
       "5                14  \n",
       "6                 6  \n",
       "7                 9  \n",
       "8                 5  \n",
       "9                 2  \n",
       "10                3  \n",
       "11               12  \n",
       "12               13  \n",
       "13               11  \n",
       "14                4  \n",
       "15                7  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state']\n",
    "rsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(alpha=0.4534492474173122, hidden_layer_sizes=76, max_iter=450,\n",
      "             random_state=13, solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "print(bestr_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=0.4534492474173122, hidden_layer_sizes=76, max_iter=450,\n",
       "             random_state=13, solver='lbfgs')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestr_mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7593244441537232\n"
     ]
    }
   ],
   "source": [
    "yhat = bestr_mlp.predict(x_va_MF) + yhat_model_va\n",
    "mae = ag_np.mean(ag_np.absolute(yhat - valid_tuple[2]))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7780449277653884\n"
     ]
    }
   ],
   "source": [
    "yhat_model_va = model.predict(valid_tuple[0], valid_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "mae_model = ag_np.mean(ag_np.absolute(yhat_model_va - valid_tuple[2]))\n",
    "print(mae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = (ag_np.concatenate((train_tuple[0], valid_tuple[0], test_tuple[0])),\n",
    "            ag_np.concatenate((train_tuple[1], valid_tuple[1], test_tuple[1])),\n",
    "            ag_np.concatenate((train_tuple[2], valid_tuple[2], test_tuple[2])))\n",
    "# Fit the model with SGD\n",
    "model.fit(all_data, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_model_final = model.predict(all_data[0], all_data[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "y_final_N = all_data[2] - yhat_model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "x_final_NF = ag_np.empty((len(all_data[0]), 106))\n",
    "for i in range(len(all_data[0])):\n",
    "    user_id = all_data[0][i]\n",
    "    item_id = all_data[1][i]\n",
    "    x_final_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_final[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][all_data[0][i]]], [user_info['is_male'][all_data[0][i]]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "bestr_mlp.fit(x_final_NF, y_final_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "select_movies_df = pd.read_csv(\"./data_movie_lens_100k/ratings_masked_leaderboard_set.csv\")\n",
    "leaderboard_user_id = select_movies_df[\"user_id\"]\n",
    "leaderboard_item_id = select_movies_df[\"item_id\"]\n",
    "\n",
    "yhat_model_preds = model.predict(leaderboard_user_id, leaderboard_item_id, pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "\n",
    "x_preds_NF = ag_np.empty((len(leaderboard_user_id), 106))\n",
    "for i in range(len(leaderboard_user_id)):\n",
    "    user_id = leaderboard_user_id[i]\n",
    "    item_id = leaderboard_item_id[i]\n",
    "    x_preds_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat_model_preds[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][leaderboard_user_id[i]]], [user_info['is_male'][leaderboard_user_id[i]]]))\n",
    "\n",
    "yhat = bestr_mlp.predict(x_preds_NF) + yhat_model_preds\n",
    "\n",
    "print(yhat)\n",
    "yhat_df = pd.DataFrame(yhat)\n",
    "print(yhat_df)\n",
    "yhat_df.to_csv(r'predicted_ratings_leaderboard.txt', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
