{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neural_network as NN\n",
    "import sklearn.model_selection\n",
    "import scipy.stats\n",
    "from AbstractBaseCollabFilterSGD import AbstractBaseCollabFilterSGD\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "    load_train_valid_test_datasets()\n",
    "user_info = pd.read_csv('./data_movie_lens_100k/user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and initialize its parameters\n",
    "# to have right scale as the dataset (right num users and items)\n",
    "model = CollabFilterOneVectorPerItem(\n",
    "    n_epochs=10, batch_size=1000, step_size=0.9,\n",
    "    alpha=0, n_factors=50)\n",
    "model.init_parameter_dict(n_users, n_items, train_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     0.97700 | train_MAE     1.00262 | valid_MAE     1.00801 | grad_wrt_mu     0.33400 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.014 | loss_total     0.94994 | train_MAE     0.96915 | valid_MAE     0.97165 | grad_wrt_mu     0.09800 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.029 | loss_total     0.94163 | train_MAE     0.95895 | valid_MAE     0.96060 | grad_wrt_mu     0.07800 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.043 | loss_total     0.97028 | train_MAE     0.95074 | valid_MAE     0.95173 | grad_wrt_mu     0.14200 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.129 | loss_total     0.85179 | train_MAE     0.91730 | valid_MAE     0.91265 | grad_wrt_mu     0.58400 | grad_wrt_b_per_user     0.00078 | grad_wrt_c_per_item     0.00044 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.257 | loss_total     0.94393 | train_MAE     0.91345 | valid_MAE     0.91205 | grad_wrt_mu     0.10200 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.386 | loss_total     0.90599 | train_MAE     0.88771 | valid_MAE     0.88458 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.500 | loss_total     0.86927 | train_MAE     0.89782 | valid_MAE     0.89609 | grad_wrt_mu     0.13600 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.629 | loss_total     0.86041 | train_MAE     0.88201 | valid_MAE     0.87932 | grad_wrt_mu     0.01800 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.757 | loss_total     0.83991 | train_MAE     0.87993 | valid_MAE     0.87771 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.886 | loss_total     0.85455 | train_MAE     0.87912 | valid_MAE     0.87669 | grad_wrt_mu     0.14200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.000 | loss_total     0.88950 | train_MAE     0.89117 | valid_MAE     0.89108 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.129 | loss_total     0.86228 | train_MAE     0.89180 | valid_MAE     0.89241 | grad_wrt_mu     0.14200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00042 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.257 | loss_total     0.84930 | train_MAE     0.87200 | valid_MAE     0.87103 | grad_wrt_mu     0.09000 | grad_wrt_b_per_user     0.00067 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.386 | loss_total     0.87515 | train_MAE     0.87057 | valid_MAE     0.87020 | grad_wrt_mu     0.08800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.500 | loss_total     0.83869 | train_MAE     0.86917 | valid_MAE     0.86915 | grad_wrt_mu     0.07000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.629 | loss_total     0.83814 | train_MAE     0.86607 | valid_MAE     0.86560 | grad_wrt_mu     0.03600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.757 | loss_total     0.86645 | train_MAE     0.86452 | valid_MAE     0.86491 | grad_wrt_mu     0.07000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.886 | loss_total     0.89274 | train_MAE     0.87197 | valid_MAE     0.87088 | grad_wrt_mu     0.25800 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.000 | loss_total     0.83689 | train_MAE     0.86398 | valid_MAE     0.86524 | grad_wrt_mu     0.12800 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.500 | loss_total     0.86384 | train_MAE     0.85301 | valid_MAE     0.85483 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.000 | loss_total     0.85523 | train_MAE     0.84884 | valid_MAE     0.85239 | grad_wrt_mu     0.11800 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.500 | loss_total     0.84696 | train_MAE     0.83896 | valid_MAE     0.84306 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.000 | loss_total     0.84137 | train_MAE     0.83386 | valid_MAE     0.83818 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.500 | loss_total     0.83839 | train_MAE     0.82799 | valid_MAE     0.83442 | grad_wrt_mu     0.04200 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.000 | loss_total     0.82794 | train_MAE     0.82050 | valid_MAE     0.82750 | grad_wrt_mu     0.02200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.500 | loss_total     0.82185 | train_MAE     0.81484 | valid_MAE     0.82247 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.000 | loss_total     0.81632 | train_MAE     0.81004 | valid_MAE     0.81942 | grad_wrt_mu     0.09800 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.500 | loss_total     0.80894 | train_MAE     0.80515 | valid_MAE     0.81557 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.000 | loss_total     0.80502 | train_MAE     0.79898 | valid_MAE     0.80961 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.500 | loss_total     0.79971 | train_MAE     0.79501 | valid_MAE     0.80659 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       8.000 | loss_total     0.79598 | train_MAE     0.79088 | valid_MAE     0.80330 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.000 | loss_total     0.78894 | train_MAE     0.78381 | valid_MAE     0.79762 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.986 | loss_total     0.78190 | train_MAE     0.77812 | valid_MAE     0.79208 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with SGD\n",
    "model.fit(train_tuple, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "yhat = model.predict(train_tuple[0], train_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "x_tr_NF = ag_np.empty((len(train_tuple[0]), 106))\n",
    "for i in range(len(train_tuple[0])):\n",
    "    user_id = train_tuple[0][i]\n",
    "    item_id = train_tuple[1][i]\n",
    "    x_tr_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][train_tuple[0][i]]], [user_info['is_male'][train_tuple[0][i]]]))\n",
    "y_tr_N = train_tuple[2]\n",
    "\n",
    "pDict = model.param_dict\n",
    "x_va_MF = ag_np.empty((len(valid_tuple[0]), 106))\n",
    "yhat = model.predict(train_tuple[0], train_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "for i in range(len(valid_tuple[0])):\n",
    "    user_id = valid_tuple[0][i]\n",
    "    item_id = valid_tuple[1][i]\n",
    "    x_va_MF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][valid_tuple[0][i]]], [user_info['is_male'][valid_tuple[0][i]]]))\n",
    "y_va_M = valid_tuple[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NN.MLPClassifier(\n",
    "    hidden_layer_sizes=[32],\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=[32], max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = mlp.predict(x_va_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7901321056845476\n"
     ]
    }
   ],
   "source": [
    "mae = ag_np.mean(ag_np.absolute(yhat - valid_tuple[2]))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_grid_by_name = dict(\n",
    "    hidden_layer_sizes=[\n",
    "        4,\n",
    "        16,\n",
    "        64,\n",
    "        ],\n",
    "    alpha=[\n",
    "        0.0,\n",
    "        0.0001,\n",
    "        0.01,\n",
    "        1.00,\n",
    "        ],\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        101, 202,\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scoring_metric_name = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_N2 = ag_np.vstack([x_tr_NF, x_va_MF])\n",
    "yall_N = ag_np.hstack([y_tr_N, y_va_M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_N = ag_np.hstack([\n",
    "    -1 * ag_np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * ag_np.ones(y_va_M.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splitter only produces one split and it is the intended one\n",
    "for tr_idx, te_idx in my_splitter.split(xall_N2, yall_N):\n",
    "    assert ag_np.allclose(xall_N2[te_idx], x_va_MF)\n",
    "    assert ag_np.allclose(yall_N[te_idx], y_va_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a custom searcher object with all our settings in place.\n",
    "#\n",
    "#grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "#    mlp,\n",
    "#    my_parameter_grid_by_name,\n",
    "#    scoring=my_scoring_metric_name,\n",
    "#    cv=my_splitter,\n",
    "#    refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_searcher.fit(xall_N2, yall_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
    "#print(\"Dataframe has shape: %s\" % (str(gsearch_results_df.shape)))\n",
    "#n_trials_grid_search = gsearch_results_df.shape[0]\n",
    "#\n",
    "#print(\"Dataframe has columns:\")\n",
    "#for c in gsearch_results_df.columns:\n",
    "#    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state']\n",
    "#\n",
    "# Rearrange row order so it is easy to skim\n",
    "#gsearch_results_df.sort_values(param_keys, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_distributions_by_name = dict(\n",
    "    hidden_layer_sizes=scipy.stats.randint(2, 70),\n",
    "    alpha=scipy.stats.uniform(0.0, 1.0),\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        13, 169,\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_rand_search = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rand_searcher = sklearn.model_selection.RandomizedSearchCV(\n",
    "    mlp,\n",
    "    my_parameter_distributions_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    n_iter=n_trials_rand_search,\n",
    "    random_state=13, # same seed means same results everytime we repeat this code\n",
    "    verbose=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n",
      "[CV] alpha=0.7777024105738202, hidden_layer_sizes=18, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7777024105738202, hidden_layer_sizes=18, random_state=13, score=-0.786, total= 2.5min\n",
      "[CV] alpha=0.8929826912712245, hidden_layer_sizes=27, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.8929826912712245, hidden_layer_sizes=27, random_state=13, score=-0.765, total= 3.1min\n",
      "[CV] alpha=0.7585840035486909, hidden_layer_sizes=28, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  8.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7585840035486909, hidden_layer_sizes=28, random_state=13, score=-0.785, total= 3.1min\n",
      "[CV] alpha=0.6073433442080506, hidden_layer_sizes=48, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 12.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6073433442080506, hidden_layer_sizes=48, random_state=13, score=-0.796, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=MLPClassifier(hidden_layer_sizes=[32],\n",
       "                                           max_iter=1000, solver='lbfgs'),\n",
       "                   n_iter=4,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f39fb95ac40>,\n",
       "                                        'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f39fb95a220>,\n",
       "                                        'random_state': [13, 169]},\n",
       "                   random_state=13, scoring='neg_mean_absolute_error',\n",
       "                   verbose=4)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rand_searcher.fit(xall_N2, yall_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (4, 12)\n",
      "Dataframe has columns:\n",
      "-- mean_fit_time\n",
      "-- std_fit_time\n",
      "-- mean_score_time\n",
      "-- std_score_time\n",
      "-- param_alpha\n",
      "-- param_hidden_layer_sizes\n",
      "-- param_random_state\n",
      "-- params\n",
      "-- split0_test_score\n",
      "-- mean_test_score\n",
      "-- std_test_score\n",
      "-- rank_test_score\n"
     ]
    }
   ],
   "source": [
    "rsearch_results_df = pd.DataFrame(my_rand_searcher.cv_results_).copy()\n",
    "print(\"Dataframe has shape: %s\" % (str(rsearch_results_df.shape)))\n",
    "\n",
    "print(\"Dataframe has columns:\")\n",
    "for c in rsearch_results_df.columns:\n",
    "    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.777702</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.785829</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>0.892983</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.764812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0.758584</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.785128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0.607343</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.796437</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_hidden_layer_sizes param_alpha param_random_state  split0_test_score  \\\n",
       "0                       18    0.777702                 13          -0.785829   \n",
       "1                       27    0.892983                 13          -0.764812   \n",
       "2                       28    0.758584                 13          -0.785128   \n",
       "3                       48    0.607343                 13          -0.796437   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                1  \n",
       "2                2  \n",
       "3                4  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state']\n",
    "rsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=0.7585840035486909, hidden_layer_sizes=28, max_iter=1000,\n",
      "              random_state=13, solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "print(bestr_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.7585840035486909, hidden_layer_sizes=28, max_iter=1000,\n",
       "              random_state=13, solver='lbfgs')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestr_mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458967173738991\n"
     ]
    }
   ],
   "source": [
    "yhat = bestr_mlp.predict(x_va_MF)\n",
    "mae = ag_np.mean(ag_np.absolute(yhat - y_va_M))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
