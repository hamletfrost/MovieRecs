{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neural_network as NN\n",
    "import sklearn.model_selection\n",
    "import scipy.stats\n",
    "from AbstractBaseCollabFilterSGD import AbstractBaseCollabFilterSGD\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "    load_train_valid_test_datasets()\n",
    "user_info = pd.read_csv('./data_movie_lens_100k/user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and initialize its parameters\n",
    "# to have right scale as the dataset (right num users and items)\n",
    "model = CollabFilterOneVectorPerItem(\n",
    "    n_epochs=10, batch_size=1000, step_size=0.9,\n",
    "    alpha=0, n_factors=50)\n",
    "model.init_parameter_dict(n_users, n_items, train_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     0.97700 | train_MAE     1.00262 | valid_MAE     1.00801 | grad_wrt_mu     0.33400 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.014 | loss_total     0.94994 | train_MAE     0.96915 | valid_MAE     0.97165 | grad_wrt_mu     0.09800 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.029 | loss_total     0.94163 | train_MAE     0.95895 | valid_MAE     0.96060 | grad_wrt_mu     0.07800 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.043 | loss_total     0.97028 | train_MAE     0.95074 | valid_MAE     0.95173 | grad_wrt_mu     0.14200 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.129 | loss_total     0.85179 | train_MAE     0.91730 | valid_MAE     0.91265 | grad_wrt_mu     0.58400 | grad_wrt_b_per_user     0.00078 | grad_wrt_c_per_item     0.00044 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.257 | loss_total     0.94393 | train_MAE     0.91345 | valid_MAE     0.91205 | grad_wrt_mu     0.10200 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.386 | loss_total     0.90599 | train_MAE     0.88771 | valid_MAE     0.88458 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.500 | loss_total     0.86927 | train_MAE     0.89782 | valid_MAE     0.89609 | grad_wrt_mu     0.13600 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.629 | loss_total     0.86041 | train_MAE     0.88201 | valid_MAE     0.87932 | grad_wrt_mu     0.01800 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.757 | loss_total     0.83991 | train_MAE     0.87993 | valid_MAE     0.87771 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.886 | loss_total     0.85455 | train_MAE     0.87912 | valid_MAE     0.87669 | grad_wrt_mu     0.14200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.000 | loss_total     0.88950 | train_MAE     0.89117 | valid_MAE     0.89108 | grad_wrt_mu     0.05800 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.129 | loss_total     0.86228 | train_MAE     0.89180 | valid_MAE     0.89241 | grad_wrt_mu     0.14200 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00042 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.257 | loss_total     0.84930 | train_MAE     0.87200 | valid_MAE     0.87103 | grad_wrt_mu     0.09000 | grad_wrt_b_per_user     0.00067 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.386 | loss_total     0.87515 | train_MAE     0.87057 | valid_MAE     0.87020 | grad_wrt_mu     0.08800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.500 | loss_total     0.83869 | train_MAE     0.86917 | valid_MAE     0.86915 | grad_wrt_mu     0.07000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.629 | loss_total     0.83814 | train_MAE     0.86607 | valid_MAE     0.86560 | grad_wrt_mu     0.03600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.757 | loss_total     0.86645 | train_MAE     0.86452 | valid_MAE     0.86491 | grad_wrt_mu     0.07000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.886 | loss_total     0.89274 | train_MAE     0.87197 | valid_MAE     0.87088 | grad_wrt_mu     0.25800 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.000 | loss_total     0.83689 | train_MAE     0.86398 | valid_MAE     0.86524 | grad_wrt_mu     0.12800 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00041 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.500 | loss_total     0.86384 | train_MAE     0.85301 | valid_MAE     0.85483 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.000 | loss_total     0.85523 | train_MAE     0.84884 | valid_MAE     0.85239 | grad_wrt_mu     0.11800 | grad_wrt_b_per_user     0.00070 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.500 | loss_total     0.84696 | train_MAE     0.83896 | valid_MAE     0.84306 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.000 | loss_total     0.84137 | train_MAE     0.83386 | valid_MAE     0.83818 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.500 | loss_total     0.83839 | train_MAE     0.82799 | valid_MAE     0.83442 | grad_wrt_mu     0.04200 | grad_wrt_b_per_user     0.00069 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.000 | loss_total     0.82794 | train_MAE     0.82050 | valid_MAE     0.82750 | grad_wrt_mu     0.02200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.500 | loss_total     0.82185 | train_MAE     0.81484 | valid_MAE     0.82247 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.000 | loss_total     0.81632 | train_MAE     0.81004 | valid_MAE     0.81942 | grad_wrt_mu     0.09800 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.500 | loss_total     0.80894 | train_MAE     0.80515 | valid_MAE     0.81557 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.000 | loss_total     0.80502 | train_MAE     0.79898 | valid_MAE     0.80961 | grad_wrt_mu     0.02000 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.500 | loss_total     0.79971 | train_MAE     0.79501 | valid_MAE     0.80659 | grad_wrt_mu     0.06400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       8.000 | loss_total     0.79598 | train_MAE     0.79088 | valid_MAE     0.80330 | grad_wrt_mu     0.03400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.000 | loss_total     0.78894 | train_MAE     0.78381 | valid_MAE     0.79762 | grad_wrt_mu     0.05200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.986 | loss_total     0.78190 | train_MAE     0.77812 | valid_MAE     0.79208 | grad_wrt_mu     0.06000 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with SGD\n",
    "model.fit(train_tuple, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "yhat = model.predict(train_tuple[0], train_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "x_tr_NF = ag_np.empty((len(train_tuple[0]), 106))\n",
    "for i in range(len(train_tuple[0])):\n",
    "    user_id = train_tuple[0][i]\n",
    "    item_id = train_tuple[1][i]\n",
    "    x_tr_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][train_tuple[0][i]]], [user_info['is_male'][train_tuple[0][i]]]))\n",
    "y_tr_N = train_tuple[2]\n",
    "\n",
    "pDict = model.param_dict\n",
    "x_va_MF = ag_np.empty((len(valid_tuple[0]), 106))\n",
    "yhat = model.predict(valid_tuple[0], valid_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "for i in range(len(valid_tuple[0])):\n",
    "    user_id = valid_tuple[0][i]\n",
    "    item_id = valid_tuple[1][i]\n",
    "    x_va_MF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][valid_tuple[0][i]]], [user_info['is_male'][valid_tuple[0][i]]]))\n",
    "y_va_M = valid_tuple[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NN.MLPClassifier(\n",
    "    hidden_layer_sizes=[32],\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=[32], max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = mlp.predict(x_va_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7501000800640513\n"
     ]
    }
   ],
   "source": [
    "mae = ag_np.mean(ag_np.absolute(yhat - valid_tuple[2]))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_grid_by_name = dict(\n",
    "    hidden_layer_sizes=[\n",
    "        4,\n",
    "        16,\n",
    "        64,\n",
    "        ],\n",
    "    alpha=[\n",
    "        0.0,\n",
    "        0.0001,\n",
    "        0.01,\n",
    "        1.00,\n",
    "        ],\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        101, 202,\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scoring_metric_name = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_N2 = ag_np.vstack([x_tr_NF, x_va_MF])\n",
    "yall_N = ag_np.hstack([y_tr_N, y_va_M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_N = ag_np.hstack([\n",
    "    -1 * ag_np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * ag_np.ones(y_va_M.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splitter only produces one split and it is the intended one\n",
    "for tr_idx, te_idx in my_splitter.split(xall_N2, yall_N):\n",
    "    assert ag_np.allclose(xall_N2[te_idx], x_va_MF)\n",
    "    assert ag_np.allclose(yall_N[te_idx], y_va_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a custom searcher object with all our settings in place.\n",
    "#\n",
    "#grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "#    mlp,\n",
    "#    my_parameter_grid_by_name,\n",
    "#    scoring=my_scoring_metric_name,\n",
    "#    cv=my_splitter,\n",
    "#    refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_searcher.fit(xall_N2, yall_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
    "#print(\"Dataframe has shape: %s\" % (str(gsearch_results_df.shape)))\n",
    "#n_trials_grid_search = gsearch_results_df.shape[0]\n",
    "#\n",
    "#print(\"Dataframe has columns:\")\n",
    "#for c in gsearch_results_df.columns:\n",
    "#    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state']\n",
    "#\n",
    "# Rearrange row order so it is easy to skim\n",
    "#gsearch_results_df.sort_values(param_keys, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_distributions_by_name = dict(\n",
    "    hidden_layer_sizes=scipy.stats.randint(2, 70),\n",
    "    alpha=scipy.stats.uniform(0.0, 1.0),\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        13, 169,\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_rand_search = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rand_searcher = sklearn.model_selection.RandomizedSearchCV(\n",
    "    mlp,\n",
    "    my_parameter_distributions_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    n_iter=n_trials_rand_search,\n",
    "    random_state=13, # same seed means same results everytime we repeat this code\n",
    "    verbose=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n",
      "[CV] alpha=0.7777024105738202, hidden_layer_sizes=18, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7777024105738202, hidden_layer_sizes=18, random_state=13, score=-0.751, total= 3.5min\n",
      "[CV] alpha=0.8929826912712245, hidden_layer_sizes=27, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.8929826912712245, hidden_layer_sizes=27, random_state=13, score=-0.750, total= 3.8min\n",
      "[CV] alpha=0.7585840035486909, hidden_layer_sizes=28, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 11.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.7585840035486909, hidden_layer_sizes=28, random_state=13, score=-0.750, total= 3.7min\n",
      "[CV] alpha=0.6073433442080506, hidden_layer_sizes=48, random_state=13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.6073433442080506, hidden_layer_sizes=48, random_state=13, score=-0.748, total= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=MLPClassifier(hidden_layer_sizes=[32],\n",
       "                                           max_iter=1000, solver='lbfgs'),\n",
       "                   n_iter=4,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f68d55d26d0>,\n",
       "                                        'hidden_layer_sizes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f68d55d3c40>,\n",
       "                                        'random_state': [13, 169]},\n",
       "                   random_state=13, scoring='neg_mean_absolute_error',\n",
       "                   verbose=4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rand_searcher.fit(xall_N2, yall_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (4, 12)\n",
      "Dataframe has columns:\n",
      "-- mean_fit_time\n",
      "-- std_fit_time\n",
      "-- mean_score_time\n",
      "-- std_score_time\n",
      "-- param_alpha\n",
      "-- param_hidden_layer_sizes\n",
      "-- param_random_state\n",
      "-- params\n",
      "-- split0_test_score\n",
      "-- mean_test_score\n",
      "-- std_test_score\n",
      "-- rank_test_score\n"
     ]
    }
   ],
   "source": [
    "rsearch_results_df = pd.DataFrame(my_rand_searcher.cv_results_).copy()\n",
    "print(\"Dataframe has shape: %s\" % (str(rsearch_results_df.shape)))\n",
    "\n",
    "print(\"Dataframe has columns:\")\n",
    "for c in rsearch_results_df.columns:\n",
    "    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.777702</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.750701</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>0.892983</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.749700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0.758584</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0.607343</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.748399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_hidden_layer_sizes param_alpha param_random_state  split0_test_score  \\\n",
       "0                       18    0.777702                 13          -0.750701   \n",
       "1                       27    0.892983                 13          -0.749700   \n",
       "2                       28    0.758584                 13          -0.750000   \n",
       "3                       48    0.607343                 13          -0.748399   \n",
       "\n",
       "   rank_test_score  \n",
       "0                4  \n",
       "1                2  \n",
       "2                3  \n",
       "3                1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state']\n",
    "rsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=0.6073433442080506, hidden_layer_sizes=48, max_iter=1000,\n",
      "              random_state=13, solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "print(bestr_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.6073433442080506, hidden_layer_sizes=48, max_iter=1000,\n",
       "              random_state=13, solver='lbfgs')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestr_mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483987189751802\n"
     ]
    }
   ],
   "source": [
    "yhat = bestr_mlp.predict(x_va_MF)\n",
    "mae = ag_np.mean(ag_np.absolute(yhat - y_va_M))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7924751255557589\n"
     ]
    }
   ],
   "source": [
    "yhat_model_va = model.predict(valid_tuple[0], valid_tuple[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "mae_model = ag_np.mean(ag_np.absolute(yhat_model_va - valid_tuple[2]))\n",
    "print(mae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     0.77816 | train_MAE     0.78087 | valid_MAE     0.79248 | grad_wrt_mu     0.03600 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.011 | loss_total     0.75376 | train_MAE     0.78065 | valid_MAE     0.79166 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.022 | loss_total     0.78273 | train_MAE     0.78052 | valid_MAE     0.79159 | grad_wrt_mu     0.04200 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.033 | loss_total     0.74704 | train_MAE     0.78186 | valid_MAE     0.79218 | grad_wrt_mu     0.07400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.133 | loss_total     0.80718 | train_MAE     0.78002 | valid_MAE     0.79163 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.256 | loss_total     0.75976 | train_MAE     0.77969 | valid_MAE     0.79143 | grad_wrt_mu     0.04400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.378 | loss_total     0.79155 | train_MAE     0.77964 | valid_MAE     0.79156 | grad_wrt_mu     0.06600 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.500 | loss_total     0.82124 | train_MAE     0.77717 | valid_MAE     0.78854 | grad_wrt_mu     0.03800 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.633 | loss_total     0.77307 | train_MAE     0.77665 | valid_MAE     0.78724 | grad_wrt_mu     0.08200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.756 | loss_total     0.75615 | train_MAE     0.77631 | valid_MAE     0.78788 | grad_wrt_mu     0.09400 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       0.878 | loss_total     0.79423 | train_MAE     0.77522 | valid_MAE     0.78569 | grad_wrt_mu     0.04800 | grad_wrt_b_per_user     0.00066 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.000 | loss_total     0.77312 | train_MAE     0.77399 | valid_MAE     0.78470 | grad_wrt_mu     0.04000 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.133 | loss_total     0.79100 | train_MAE     0.77328 | valid_MAE     0.78396 | grad_wrt_mu     0.00600 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00040 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.256 | loss_total     0.78978 | train_MAE     0.77387 | valid_MAE     0.78365 | grad_wrt_mu     0.11200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.378 | loss_total     0.78456 | train_MAE     0.77299 | valid_MAE     0.78279 | grad_wrt_mu     0.10000 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.500 | loss_total     0.74651 | train_MAE     0.77121 | valid_MAE     0.78162 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.633 | loss_total     0.76781 | train_MAE     0.77105 | valid_MAE     0.78102 | grad_wrt_mu     0.03600 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.756 | loss_total     0.76739 | train_MAE     0.77029 | valid_MAE     0.78024 | grad_wrt_mu     0.03600 | grad_wrt_b_per_user     0.00061 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       1.878 | loss_total     0.77037 | train_MAE     0.76936 | valid_MAE     0.77949 | grad_wrt_mu     0.01200 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.000 | loss_total     0.76851 | train_MAE     0.76868 | valid_MAE     0.77895 | grad_wrt_mu     0.03000 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       2.500 | loss_total     0.77048 | train_MAE     0.76636 | valid_MAE     0.77650 | grad_wrt_mu     0.05400 | grad_wrt_b_per_user     0.00067 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.000 | loss_total     0.76814 | train_MAE     0.76506 | valid_MAE     0.77536 | grad_wrt_mu     0.06600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       3.500 | loss_total     0.76578 | train_MAE     0.76355 | valid_MAE     0.77369 | grad_wrt_mu     0.00400 | grad_wrt_b_per_user     0.00068 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.000 | loss_total     0.76328 | train_MAE     0.76050 | valid_MAE     0.76993 | grad_wrt_mu     0.04600 | grad_wrt_b_per_user     0.00060 | grad_wrt_c_per_item     0.00039 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       4.500 | loss_total     0.76025 | train_MAE     0.75872 | valid_MAE     0.76772 | grad_wrt_mu     0.00200 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.000 | loss_total     0.76028 | train_MAE     0.76010 | valid_MAE     0.76980 | grad_wrt_mu     0.01600 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       5.500 | loss_total     0.75861 | train_MAE     0.75573 | valid_MAE     0.76420 | grad_wrt_mu     0.04200 | grad_wrt_b_per_user     0.00064 | grad_wrt_c_per_item     0.00034 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.000 | loss_total     0.75669 | train_MAE     0.75516 | valid_MAE     0.76419 | grad_wrt_mu     0.10800 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       6.500 | loss_total     0.75744 | train_MAE     0.75352 | valid_MAE     0.76160 | grad_wrt_mu     0.01400 | grad_wrt_b_per_user     0.00062 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.000 | loss_total     0.75494 | train_MAE     0.75177 | valid_MAE     0.76003 | grad_wrt_mu     0.01000 | grad_wrt_b_per_user     0.00065 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       7.500 | loss_total     0.75287 | train_MAE     0.75074 | valid_MAE     0.75911 | grad_wrt_mu     0.01800 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00037 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       8.000 | loss_total     0.75181 | train_MAE     0.74954 | valid_MAE     0.75772 | grad_wrt_mu     0.01600 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00036 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.000 | loss_total     0.74978 | train_MAE     0.74749 | valid_MAE     0.75549 | grad_wrt_mu     0.02200 | grad_wrt_b_per_user     0.00059 | grad_wrt_c_per_item     0.00038 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n",
      "epoch       9.989 | loss_total     0.74777 | train_MAE     0.74693 | valid_MAE     0.75527 | grad_wrt_mu     0.07460 | grad_wrt_b_per_user     0.00063 | grad_wrt_c_per_item     0.00035 | grad_wrt_U     0.00000 | grad_wrt_V     0.00000\n"
     ]
    }
   ],
   "source": [
    "all_data = (ag_np.concatenate((train_tuple[0], valid_tuple[0], test_tuple[0])),\n",
    "            ag_np.concatenate((train_tuple[1], valid_tuple[1], test_tuple[1])),\n",
    "            ag_np.concatenate((train_tuple[2], valid_tuple[2], test_tuple[2])))\n",
    "# Fit the model with SGD\n",
    "model.fit(all_data, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDict = model.param_dict\n",
    "yhat = model.predict(all_data[0], all_data[1], pDict['mu'], pDict['b_per_user'], pDict['c_per_item'], pDict['U'], pDict['V'])\n",
    "x_final_NF = ag_np.empty((len(all_data[0]), 106))\n",
    "for i in range(len(all_data[0])):\n",
    "    user_id = all_data[0][i]\n",
    "    item_id = all_data[1][i]\n",
    "    x_final_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][all_data[0][i]]], [user_info['is_male'][all_data[0][i]]]))\n",
    "y_final_N = all_data[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.6073433442080506, hidden_layer_sizes=48, max_iter=1000,\n",
       "              random_state=13, solver='lbfgs')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "bestr_mlp.fit(x_final_NF, y_final_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 3 ... 4 4 3]\n",
      "      0\n",
      "0     4\n",
      "1     4\n",
      "2     3\n",
      "3     4\n",
      "4     4\n",
      "...  ..\n",
      "9995  4\n",
      "9996  4\n",
      "9997  4\n",
      "9998  4\n",
      "9999  3\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "select_movies_df = pd.read_csv(\"./data_movie_lens_100k/ratings_masked_leaderboard_set.csv\")\n",
    "leaderboard_user_id = select_movies_df[\"user_id\"]\n",
    "leaderboard_item_id = select_movies_df[\"item_id\"]\n",
    "\n",
    "x_preds_NF = ag_np.empty((len(leaderboard_user_id), 106))\n",
    "for i in range(len(leaderboard_user_id)):\n",
    "    user_id = leaderboard_user_id[i]\n",
    "    item_id = leaderboard_item_id[i]\n",
    "    x_preds_NF[i] = ag_np.concatenate((pDict['U'][user_id], pDict['V'][item_id], [yhat[i]],\n",
    "                                    pDict['mu'], [pDict['b_per_user'][user_id]], [pDict['c_per_item'][item_id]],\n",
    "                                    [user_info['age'][leaderboard_user_id[i]]], [user_info['is_male'][leaderboard_user_id[i]]]))\n",
    "\n",
    "yhat = bestr_mlp.predict(x_preds_NF)\n",
    "\n",
    "print(yhat)\n",
    "yhat_df = pd.DataFrame(yhat)\n",
    "print(yhat_df)\n",
    "yhat_df.to_csv(r'predicted_ratings_leaderboard.txt', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
