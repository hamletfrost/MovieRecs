{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neural_network as NN\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import scipy.stats\n",
    "from AbstractBaseCollabFilterSGD import AbstractBaseCollabFilterSGD\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "    load_train_valid_test_datasets()\n",
    "user_info = pd.read_csv('./data_movie_lens_100k/user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = (ag_np.concatenate((train_tuple[0], valid_tuple[0], test_tuple[0])),\n",
    "            ag_np.concatenate((train_tuple[1], valid_tuple[1], test_tuple[1])),\n",
    "            ag_np.concatenate((train_tuple[2], valid_tuple[2], test_tuple[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and initialize its parameters\n",
    "# to have right scale as the dataset (right num users and items)\n",
    "model = CollabFilterOneVectorPerItem(\n",
    "    n_epochs=156, batch_size=508, step_size=0.8108726428612864,\n",
    "    alpha=0.061177501974355154, n_factors=170)\n",
    "model.init_parameter_dict(n_users, n_items, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with SGD\n",
    "model.fit(all_data, valid_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = model.param_dict['U']\n",
    "x_tr_NF = U[train_tuple[0]]\n",
    "x_va_MF = U[valid_tuple[0]]\n",
    "x_te_LF = U[test_tuple[0]]\n",
    "\n",
    "y_tr_N = user_info['is_male'][train_tuple[0]]\n",
    "y_va_M = user_info['is_male'][valid_tuple[0]]\n",
    "y_te_L = user_info['is_male'][test_tuple[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NN.MLPClassifier(\n",
    "    hidden_layer_sizes=[32],\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_te_L = mlp.predict(x_te_LF)\n",
    "BA = sklearn.metrics.balanced_accuracy_score(y_te_L, yhat_te_L)\n",
    "print(BA)\n",
    "print(yhat_te_L[0:10])\n",
    "print(y_te_L[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scoring_metric_name = 'balanced_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_search_NFpMF = ag_np.vstack([x_tr_NF, x_va_MF])\n",
    "y_search_NpM = ag_np.hstack([y_tr_N, y_va_M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_NpM = ag_np.hstack([\n",
    "    -1 * ag_np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * ag_np.ones(y_va_M.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_NpM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splitter only produces one split and it is the intended one\n",
    "for tr_idx, te_idx in my_splitter.split(x_search_NFpMF, y_search_NpM):\n",
    "    assert ag_np.allclose(x_search_NFpMF[te_idx], x_va_MF)\n",
    "    assert ag_np.allclose(y_search_NpM[te_idx], y_va_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_distributions_by_name = dict(\n",
    "    hidden_layer_sizes=scipy.stats.randint(10, 150),\n",
    "    alpha=scipy.stats.uniform(0.0, 1.0),\n",
    "    random_state=[  # try two possible seeds to initialize parameters\n",
    "        13, 169,\n",
    "        ],\n",
    "    max_iter=scipy.stats.randint(20, 1000)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_rand_search = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rand_searcher = sklearn.model_selection.RandomizedSearchCV(\n",
    "    mlp,\n",
    "    my_parameter_distributions_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    n_iter=n_trials_rand_search,\n",
    "    random_state=13, # same seed means same results everytime we repeat this code\n",
    "    verbose=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rand_searcher.fit(x_search_NFpMF, y_search_NpM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsearch_results_df = pd.DataFrame(my_rand_searcher.cv_results_).copy()\n",
    "print(\"Dataframe has shape: %s\" % (str(rsearch_results_df.shape)))\n",
    "\n",
    "print(\"Dataframe has columns:\")\n",
    "for c in rsearch_results_df.columns:\n",
    "    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keys = ['param_hidden_layer_sizes', 'param_alpha', 'param_random_state', 'param_max_iter']\n",
    "rsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=0.7777024105738202, hidden_layer_sizes=[84], max_iter=548,\n",
      "              random_state=13, solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "#bestr_mlp = mlp.set_params(**my_rand_searcher.best_params_)\n",
    "bestr_mlp = NN.MLPClassifier(\n",
    "    alpha=0.7777024105738202,\n",
    "    hidden_layer_sizes=[84],\n",
    "    solver='lbfgs',\n",
    "    max_iter=548,\n",
    "    random_state=13)\n",
    "print(bestr_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.7777024105738202, hidden_layer_sizes=[84], max_iter=548,\n",
       "              random_state=13, solver='lbfgs')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestr_mlp.fit(x_search_NFpMF, y_search_NpM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "yhat_te_L = bestr_mlp.predict(x_te_LF)\n",
    "BA = sklearn.metrics.balanced_accuracy_score(y_te_L, yhat_te_L)\n",
    "print(BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2558    0]\n",
      " [   0 7442]]\n"
     ]
    }
   ],
   "source": [
    "CM = sklearn.metrics.confusion_matrix(y_te_L, yhat_te_L)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7442\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_te_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestr_mlp.fit(x_te_LF, y_te_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_search_NpM = bestr_mlp.predict(x_search_NFpMF)\n",
    "BA = sklearn.metrics.balanced_accuracy_score(y_search_NpM, yhat_search_NpM)\n",
    "print(BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
